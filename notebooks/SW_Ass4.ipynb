{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************************************************\n",
    "# The Social Web Assignment 4: Recommendation\n",
    "\n",
    "- Instructors: Davide Ceolin, Emma Beauxis-Aussalet.\n",
    "- TAs: Zubaria Inayat, Maxim Sergeev, Zhuofan Mei, Alexander Schmatz, Ling Jin.\n",
    "- Exercises for Hands-on session 4 \n",
    "*****************************************************\n",
    "\n",
    "In this notebook you will use the similarity measures to provide recommendations by comparing users and content based on expressed preferences (ratings). You will also explore textual similarity using a very popular natural language processing library, NLTK. Finally, you will explore recommendations on the Reddit platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required packages:\n",
    "* feedparser, praw,  nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "!pip install feedparser\n",
    "!pip install praw\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the snippets below, you can find:\n",
    "* creation of a small toy database in form of a dictionary of dictionaries;\n",
    "* issuing several similarity measures based on critics' preferences; and\n",
    "* use those values to obtain meaningful statistics pertaining a user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie preferences of movie critics\n",
    "As example data, let us define a python dictionary of movie critics and their ratings of a small set of movies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critics = {\n",
    "    'Lisa Rose': {\n",
    "        'Lady in the Water': 2.5,\n",
    "        'Snakes on a Plane': 3.5,\n",
    "        'Just My Luck': 3.0,\n",
    "        'Superman Returns': 3.5,\n",
    "        'You, Me and Dupree': 2.5,\n",
    "        'The Night Listener': 3.0,\n",
    "    },\n",
    "    'Gene Seymour': {\n",
    "        'Lady in the Water': 3.0,\n",
    "        'Snakes on a Plane': 3.5,\n",
    "        'Just My Luck': 1.5,\n",
    "        'Superman Returns': 5.0,\n",
    "        'The Night Listener': 3.0,\n",
    "        'You, Me and Dupree': 3.5,\n",
    "    },\n",
    "    'Michael Phillips': {\n",
    "        'Lady in the Water': 2.5,\n",
    "        'Snakes on a Plane': 3.0,\n",
    "        'Superman Returns': 3.5,\n",
    "        'The Night Listener': 4.0,\n",
    "    },\n",
    "    'Claudia Puig': {\n",
    "        'Snakes on a Plane': 3.5,\n",
    "        'Just My Luck': 3.0,\n",
    "        'The Night Listener': 4.5,\n",
    "        'Superman Returns': 4.0,\n",
    "        'You, Me and Dupree': 2.5,\n",
    "    },\n",
    "    'Mick LaSalle': {\n",
    "        'Lady in the Water': 3.0,\n",
    "        'Snakes on a Plane': 4.0,\n",
    "        'Just My Luck': 2.0,\n",
    "        'Superman Returns': 3.0,\n",
    "        'The Night Listener': 3.0,\n",
    "        'You, Me and Dupree': 2.0,\n",
    "    },\n",
    "    'Jack Matthews': {\n",
    "        'Lady in the Water': 3.0,\n",
    "        'Snakes on a Plane': 4.0,\n",
    "        'The Night Listener': 3.0,\n",
    "        'Superman Returns': 5.0,\n",
    "        'You, Me and Dupree': 3.5,\n",
    "    },\n",
    "    'Toby': {'Snakes on a Plane': 4.5, \n",
    "             'You, Me and Dupree': 1.0,\n",
    "             'Superman Returns': 4.0},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exercise 1: Finding Similar Users**\n",
    "\n",
    "In the code below, two different simililarity measures are used: Euclidean distance and the Pearson correlation. If you are not familiar with them, we recommend you look them up to deepen your understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euclidian distance"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess the degree similarity between critics given their respective preferences, we can use the euclidian distance.\n",
    "Its formula for an N-dimensional space is is: ![image.png](attachment:image.png)\n",
    "Because we want a smaller distance to indicate a larger similarity, we will use 1/d(p,q) as our similarity value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def sim_distance(p1, p2, show_common_dims=False, prefs=critics):\n",
    "    '''\n",
    "    Returns a distance-based similarity score between two critics.\n",
    "    '''\n",
    "\n",
    "    # Get the list of shared_items\n",
    "    common_items = []\n",
    "    for movie in prefs[p1]:\n",
    "        if movie in prefs[p2]:\n",
    "            common_items.append(movie)\n",
    "    # If they have no ratings in common, return 0\n",
    "    if len(common_items) == 0:\n",
    "        return 0\n",
    "    if show_common_dims:\n",
    "        print(\"common dimensions between {} and {}: \".format(p1, p2) + str(len(common_items)))\n",
    "    # Add up the squares of all the differences\n",
    "    sum_of_squares = sum([pow(prefs[p1][movie] - prefs[p2][movie], 2) for movie in common_items])\n",
    "    \n",
    "    # return sqrt(sum_of_squares)\n",
    "    return 1 / sqrt(sum_of_squares)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this simple formula, you can calculate a similarity between two critics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the distance between 'Lisa Rose' and 'Gene Seymour'\n",
    "sim_distance('Lisa Rose','Gene Seymour') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try this with other names so you can see who is closer or further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name at least two problems with the sim_distance function as it is defined above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problems:\n",
    "1. If two critics generally judge the same movies as good or bad, but one is a bit more strict (so gives more lower grades), they\n",
    "will be dissimilar with this distcance.\n",
    "2. One movie that they rate differently will increase the distance by a lot\n",
    "3. not normalized so distance tends to increase with increased movie size\n",
    "    "
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A different measure of similarity can be given by pearson correlation.\n",
    "Which follows: ![image.png](attachment:image.png)\n",
    "\n",
    "Where the dividend represents a measure of covariance between dimensions, whereas the divisor is the product of the standard deviation of the scores given by each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_pearson(p1, p2, prefs=critics, verbose=False):\n",
    "    '''\n",
    "    Returns the Pearson correlation coefficient for p1 and p2.\n",
    "    '''\n",
    "\n",
    "    '''Step 1: Get the list of mutually rated items'''\n",
    "    common_items = []\n",
    "    dic = {}\n",
    "    for movie in prefs[p1]:\n",
    "        if movie in prefs[p2]:\n",
    "            common_items.append(movie)\n",
    "    # If they are no ratings in common, return 0\n",
    "    if len(common_items) == 0:\n",
    "        return 0\n",
    "    '''Step 2: Sum calculations'''\n",
    "    n_common_items = len(common_items)\n",
    "    sum1 = sum([prefs[p1][movie] for movie in common_items])\n",
    "    sum2 = sum([prefs[p2][movie] for movie in common_items])\n",
    "    # Sums of squares\n",
    "    sum1Sq = sum([pow(prefs[p1][movie], 2) for movie in common_items])\n",
    "    sum2Sq = sum([pow(prefs[p2][movie], 2) for movie in common_items])\n",
    "    # Sum of the products\n",
    "    pSum = sum([prefs[p1][movie] * prefs[p2][movie] for movie in common_items])\n",
    "    # Calculate r (Pearson score)\n",
    "    num = pSum - sum1 * sum2 / n_common_items\n",
    "    den = sqrt((sum1Sq - pow(sum1, 2) / n_common_items) * (sum2Sq - pow(sum2, 2) / n_common_items))\n",
    "    if den == 0:\n",
    "        return 0\n",
    "    r = num / den\n",
    "    if verbose:\n",
    "        print(\"common dimensions: %s\" % len(common_items))\n",
    "        print(\"Similarity Score for {} and {}: {}\".format(p1, p2, r))\n",
    "    return r\n",
    "\n",
    "# for k in critics.keys():\n",
    "#     sim_pearson('Michael Phillips', k, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the examples you used for the eucledian distance again, but now using the pearson correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_pearson('Lisa Rose','Gene Seymour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking critics on similarity\n",
    "The topMatches function below calculates all similarities of a given critic with his peers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topMatches(person, n=5, similarity=sim_pearson, prefs=critics):\n",
    "    '''\n",
    "    Returns the best matches for person from the prefs dictionary. \n",
    "    Number of results and similarity function are optional params.\n",
    "    '''\n",
    "    if similarity not in [sim_distance, sim_pearson]:\n",
    "        # NB: here we are comparing FUNCTION DEFINITION.\n",
    "        # We do that only in a jupyter notebook for the sake of simplicity.\n",
    "        raise ValueError(\"Callback functions should be: 'sim_pearson' or 'sim_distance'.\")\n",
    "        \n",
    "    scores = [(similarity(person, other, prefs=prefs), other) for other in prefs\n",
    "              if other != person]\n",
    "    scores.sort()\n",
    "    scores.reverse()\n",
    "    return scores[0:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So you can now get the 3 critics closest to Toby by calling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topMatches('Toby',n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "*****************************************************\n",
    "### Task: Effect of similarity function used\n",
    "Call the topMatches function on a number of critics with both the default sim_pearson, but also with the sim_distance function. Would you have preference of one over the other? \n",
    "*****************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for critic in critics.keys():\n",
    "    print(critic)\n",
    "    print(topMatches(critic,n=3))\n",
    "    print(topMatches(critic,n=3,similarity=sim_distance))\n",
    "    print(\"_____________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe differences found here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use pearson because of the ordinal nature of movie data.\n",
    "Furthermore, its scale irrelevatn (described above) and directional relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 2: Recommending Items**\n",
    "\n",
    "One way to recommend movies to a person would be to rate the movies she has not seen yet by using the scores of the others weighted by the similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRecommendations(person, similarity=sim_pearson, prefs=critics):\n",
    "    '''\n",
    "    Gets recommendations for a person by using a weighted average\n",
    "    of every other user's rankings\n",
    "    '''\n",
    "    if similarity not in [sim_distance, sim_pearson]:\n",
    "        raise ValueError(\"Callback functions should be: 'sim_pearson' or 'sim_distance'.\")\n",
    "\n",
    "    totals = {}\n",
    "    simSums = {}\n",
    "    for other in prefs:\n",
    "    # Don't compare me to myself\n",
    "        if other == person:\n",
    "            continue\n",
    "        # print(person, other)\n",
    "        sim = similarity(person, other, prefs=prefs)\n",
    "    # Ignore scores of zero or lower\n",
    "        if sim <= 0: \n",
    "            continue\n",
    "        for item in prefs[other]:\n",
    "            # Only score movies I haven't seen yet\n",
    "            if item not in prefs[person] or prefs[person][item] == 0:\n",
    "                # Similarity * Score\n",
    "                    totals.setdefault(item, 0)\n",
    "                    # The final score is calculated by multiplying each item by the\n",
    "                    #   similarity and adding these products together\n",
    "                    totals[item] += prefs[other][item] * sim\n",
    "                    # Sum of similarities\n",
    "                    simSums.setdefault(item, 0)\n",
    "                    simSums[item] += sim\n",
    "    # Create the normalized list\n",
    "    rankings = [(total / simSums[item], item) for (item, total) in\n",
    "                totals.items()]\n",
    "    # Return the sorted list\n",
    "    rankings.sort()\n",
    "    rankings.reverse()\n",
    "    return rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getRecommendations('Toby', similarity=sim_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getRecommendations('Toby')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the output does not only consist of a movie title, but also a guess at what the user's rating for each movie would be.\n",
    "\n",
    "*****************************************************\n",
    "### Task: Explainable recommendations\n",
    "Can you also find out how to give information on how the recommendation is built up. For example about the 'closest' person that also watched this movie?\n",
    "*****************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# \n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "getRecommendations_plus('Toby')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 3: Transformations** \n",
    "**You have been building recommendations based on similar users in Exercise 2, but you could of course also build recommendations based on similar items. In this exercise you will do this.** \n",
    "\n",
    "The function is essentially the same, but you need to transfer your data, from:\n",
    "\n",
    "<code>{'Lisa Rose': {'Lady in the Water': 2.5, 'Snakes on a Plane': 3.5},\n",
    "'Gene Seymour': {'Lady in the Water': 3.0, 'Snakes on a Plane': 3.5}}</code>\n",
    "\n",
    "to\n",
    "\n",
    "<code>{'Lady in the Water': {'Lisa Rose': 2.5,'Gene Seymour': 3.0},\n",
    "'Snakes on a Plane': {'Lisa Rose': 3.5,'Gene Seymour': 3.5}}</code>\n",
    "\n",
    "This is what the transformPrefs function does. \n",
    "\n",
    "You can now create a dictionary for movies with their scores assigned by different people by invoking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformPrefs(prefs=critics):\n",
    "    '''\n",
    "    Transform the recommendations into a mapping where persons are described\n",
    "    with interest scores for a given title e.g. {title: person} instead of\n",
    "    {person: title}.\n",
    "    '''\n",
    "    result = {}\n",
    "    for person in prefs:\n",
    "        for item in prefs[person]:\n",
    "            result.setdefault(item, {})\n",
    "            # Flip item and person\n",
    "            result[item][person] = prefs[person][item]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = transformPrefs()\n",
    "print(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And find similar items for a particular movie like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topMatches('Superman Returns', prefs=movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or find people who may like a particular movie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "getRecommendations('Just My Luck', prefs=movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "*****************************************************\n",
    "#### Task: why does the example above work?\n",
    "Try to follow exactly what is going on in the last call. Notice that Michael and Jack did not rate 'Just my Luck'. How is their rating for it built up?\n",
    "*****************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the dataset has been restructured to a movie-centric format (movie:user:rating).\n",
    "So the similarity functions calculate for each user who has not rated 'Just My Luck', a similarity score with those who have rated it. The similarity score is based on how similarly two users rate other movies they've both seen.\n",
    "For each user who hasn't seen 'Just My Luck', the function estimates a rating by weighted averaging. It does this by taking each rating of 'Just My Luck' by other users, multiplying these ratings by the similarity score between the non-rater and the rater, and summing these products.\n",
    "The result is a list of users with their estimated enjoyment of 'Just My Luck', ranked from highest to lowest.\n",
    "In the case of Michael and Jack, who did not rate 'Just My Luck', the function predicts their rating for the movie based on how similar their tastes are to those who have rated the movie. If Michael, for example, has tastes very similar to users who liked 'Just My Luck', then the predicted rating for Michael will be high. Conversely, if his tastes align more with users who rated the movie poorly, the predicted rating will be lower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 4: Sentence Similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import natural language processing software we need later.\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download wordnet and punkt sentence tokenizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we have some example sentences to compare later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = [\"I saw a really good movie last night.\",\n",
    "\"The movie is based on the director's life.\",\n",
    "\"The movie starts at ten.\",\n",
    "\"I took her to a movie.\",\n",
    "\"The movie stars Al Pacino.\",\n",
    "\"The movie opened last weekend.\",\n",
    "\"The movie lasted two hours.\",\n",
    "\"He directed several movies.\", \n",
    "\"We just shot another movie.\", \n",
    "\"The movie was set in New York.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jaccard_sim(str1, str2): \n",
    "    a = set(str1.split()) \n",
    "    b = set(str2.split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the Jaccard Similarity of two sentences however, we first need to do some preprocessing in the form of Lemmatization and Tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(s1, s2):\n",
    "\n",
    "    #Import a Lemmatizer to get the root form of certain words\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    \n",
    "    #Tokenize both sentences to get each word separately\n",
    "    word_list1 = nltk.word_tokenize(s1)\n",
    "    word_list2 = nltk.word_tokenize(s2)\n",
    "    \n",
    "#     print(\"Tokenized sentence\", word_list1) #Uncomment to see an example of the tokenized sentence \n",
    "    \n",
    "    #Lemmatize both sentences\n",
    "    lemmatized_output1 = ' '.join([lemmatizer.lemmatize(w, 'v') for w in word_list1])\n",
    "    lemmatized_output2 = ' '.join([lemmatizer.lemmatize(w, 'v') for w in word_list2])\n",
    "    #print(lemmatized_output2)\n",
    "    return lemmatized_output1, lemmatized_output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "for x in range(len(movies)):\n",
    "    l1, l2 = compare(movies[0], movies[x])\n",
    "    print(\"Sentence 1:\", l1, '\\n', \"Sentence 2:\", l2, '\\n', \"Similarity Score:\", get_jaccard_sim(l1,l2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************************************************\n",
    "#### Task: In what scenario's could the Jaccard Similarity be more useful than the Euclidean distance and the Pearson Similarity metrics? Why is that? \n",
    "*****************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The jaccard similarity measures similarity between sets by dividing the intersection by the union of two sets. So in a case where two sets are 100% identical union and intersection are identical == 1. If they do not have any shared elements, then the intersection is empty so 0/some number == 0. For comparisons where it is hard to give definete real values (as we have the case here), the jaccard similarity is a better pick. A possible solution would be to one hot encode appearing words to apply pearson/euclidean similarity, but with more extensive vocabulary these measure start to fail quickly as the vectors tend to get very scarce (Curse of Dimensionality: With increasing dimensions, Euclidean distances tend to become less meaningful, and the Pearson correlation can be less informative due to the lack of variance in most dimensions). Also: jaccard distance better at Handling Outliers and Non-Normal Distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 5: Building a Reddit Recommender**\n",
    "\n",
    "After having created your Reddit account, go to User Settings -> Safety & Privacy -> Manage third-party app authorization.\n",
    "Here, you will create your own app. Give it a name, and add \"https://www.reddit.com/prefs/apps/ \" to the redirect uri. Keep the other settings as they are.\n",
    "You may encounter some issues accessing \"https://www.reddit.com/prefs/apps/ \" in Chrome. If so, try with another browser.\n",
    "\n",
    "* replace the '???' in the user_agent string with your name (or any unique string).\n",
    "* replace the '???' in the client_id with the id right underneath your web app name.\n",
    "* replace the '???' in the client_secret with the key next to 'secret'.\n",
    "\n",
    "NOTE: install praw v. 3.5 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import praw\n",
    "import time\n",
    "\n",
    "#Delete keys before handing in the notebook\n",
    "r = praw.Reddit(user_agent=???, client_id=???,\n",
    "                      client_secret=???,\n",
    "                      redirect_url='https://www.reddit.com/prefs/apps/'\n",
    "                                   'authorize_callback')\n",
    "\n",
    "\n",
    "def initializeUserDict(subreddit, count=10):\n",
    "    user_dict={}\n",
    "    # get the top count' popular posts\n",
    "    for post in r.subreddit(subreddit).top(limit=count):\n",
    "        # find all users who commented in this\n",
    "        flat_comments = post.comments.list()\n",
    "        for comment in flat_comments:\n",
    "            try:\n",
    "                user = comment.author.name\n",
    "                user_dict[user] = {}\n",
    "            except AttributeError:\n",
    "                pass\n",
    "    return user_dict\n",
    "\n",
    "def fillItems(user_dict, count=100):\n",
    "    all_items={}\n",
    "    # Find links posted by all users\n",
    "    for user in user_dict:\n",
    "        # print(\"finding subreddits where user \" + user + \"has commented\")\n",
    "        # find new comments for given user\n",
    "        comments = r.redditor(user).comments.new(limit=count)\n",
    "        for c in comments:\n",
    "            # Get the subreddit where the comment was made\n",
    "            subreddit = c.subreddit\n",
    "            sub_name = subreddit.display_name\n",
    "            # print(sub_name)\n",
    "            if sub_name in user_dict[user]:\n",
    "                user_dict[user][sub_name] += 1.0\n",
    "            else:\n",
    "                user_dict[user][sub_name] = 1.0\n",
    "            \n",
    "            all_items[sub_name] = 1\n",
    "#     Fill in missing items with 0\n",
    "#     for subr_counts in user_dict.values():\n",
    "#         for item in all_items:\n",
    "#             if item not in subr_counts:\n",
    "#                 subr_counts[item]=0.0\n",
    "    \n",
    "    return user_dict\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get a list of popular recent posts about programming from the programming subreddit (https://www.reddit.com/r/VUAmsterdam) by invoking the code below.  Don't forget to replace the '???' in the user_agent string with your name (or any unique string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"praw version == \" + praw.__version__)\n",
    "\n",
    "subreddit = r.subreddit(\"programming\")\n",
    "for post in r.subreddit('VUAmsterdam').top(limit=5):\n",
    "    print(end='\\n * ')\n",
    "    print(post.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See here a list of other subreddits you can explore with this code: https://www.reddit.com/reddits/\n",
    "\n",
    "To automatically create a data set of reddit users similar to the movie watchers you can invoke the initializeUserDict function in redditrec.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "red_users=initializeUserDict('VUAmsterdam', count=10) # or for any other subreddit\n",
    "print(red_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now initializeUserDict has only created the user keys. We of course also want to know what subreddits they posted comments on. You can pull those in through:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dict_ = fillItems(red_users, count=50)\n",
    "# here you can see how often each user commented in what sub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script may take a few minutes to collect all the data. Use this time to review what is going on in the code. Notice that users don't give ratings to subreddits, instead we are counting how many comments they posted in each subreddit. \n",
    "\n",
    "To recommend a similar user, we can use our topMatches function again.\n",
    "\n",
    "First choose a random user for whom you're going to find neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "user= random.choice( list( red_users.keys() ))\n",
    "print(user) # print the username \n",
    "topMatches(user, prefs=red_users) # from all redditors, get the most similar to user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If no similar user was found, you can try increasing the count of users or comments for each initializeUserDict and fillItems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************************************************\n",
    "#### Task: Recommend subreddits for a user based on what subreddits similar users have commented in. Recommend posts for a user based on posts they have commented on. \n",
    "*****************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def jaccard_similarity(user1, user2, prefs):\n",
    "    # Extracting the sets of subreddits for each user\n",
    "    set1 = set(prefs[user1].keys())\n",
    "    set2 = set(prefs[user2].keys())\n",
    "\n",
    "    # Calculating intersection and union\n",
    "    intersection = set1.intersection(set2)\n",
    "    union = set1.union(set2)\n",
    "\n",
    "    # Handling division by zero in case both sets are empty\n",
    "    if len(union) == 0:\n",
    "        return 0\n",
    "\n",
    "    # Calculating Jaccard Similarity\n",
    "    return len(intersection) / len(union)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getRecommendations1(target_user, prefs):\n",
    "    totals = {}\n",
    "    simSums = {}\n",
    "\n",
    "    for other_user in prefs:\n",
    "        # Skip similarity with self\n",
    "        if other_user == target_user:\n",
    "            continue\n",
    "\n",
    "        sim = jaccard_similarity(target_user, other_user, prefs)\n",
    "\n",
    "        # Ignore scores of zero or lower\n",
    "        if sim <= 0:\n",
    "            continue\n",
    "\n",
    "        for subreddit in prefs[other_user]:\n",
    "            # Recommend only subreddits target user hasn't commented on\n",
    "            if subreddit not in prefs[target_user] or prefs[target_user][subreddit] == 0:\n",
    "                # Similarity * Comment Frequency\n",
    "                totals.setdefault(subreddit, 0)\n",
    "                totals[subreddit] += prefs[other_user][subreddit] * sim\n",
    "                # Sum of similarities\n",
    "                simSums.setdefault(subreddit, 0)\n",
    "                simSums[subreddit] += sim\n",
    "\n",
    "    # Create a normalized list\n",
    "    rankings = [(total / simSums[subreddit], subreddit) for subreddit, total in totals.items()]\n",
    "\n",
    "    # Return the sorted list\n",
    "    rankings.sort(reverse=True)\n",
    "    return rankings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "getRecommendations1(\"alecsferra\",dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fillItems1(user_dict, count=100):\n",
    "    all_items = {}\n",
    "    # Find comments made by all users\n",
    "    for user in user_dict:\n",
    "        # Find new comments for the given user\n",
    "        comments = r.redditor(user).comments.new(limit=count)\n",
    "        for comment in comments:\n",
    "            # Get the submission (post) where the comment was made\n",
    "            submission = comment.submission\n",
    "            print(submission_id)\n",
    "            submission_id = submission.id\n",
    "            print(submission_id)\n",
    "            if submission_id in user_dict[user]:\n",
    "                user_dict[user][submission_id] += 1.0\n",
    "            else:\n",
    "                user_dict[user][submission_id] = 1.0\n",
    "\n",
    "            all_items[submission_id] = 1\n",
    "    \n",
    "    return user_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "red_users=initializeUserDict('VUAmsterdam', count=10) # or for any other subreddit\n",
    "print(red_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dict_ = fillItems1(red_users, count=50)\n",
    "# here you can see how often each user commented in what sub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "getRecommendations1(\"Honey_2525\",dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "post = r.submission(id=\"pf9bv4\")\n",
    "\n",
    "# Print information about the post\n",
    "print(\"Post Title:\", post.title)\n",
    "print(\"Author:\", post.author)\n",
    "print(\"Subreddit:\", post.subreddit.display_name)\n",
    "print(\"Score:\", post.score)\n",
    "print(\"Number of Comments:\", post.num_comments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
